@ARTICLE {10123038,
author = {P. Xu and X. Zhu and D. A. Clifton},
journal = {IEEE Transactions on Pattern Analysis &amp; Machine Intelligence},
title = {Multimodal Learning With Transformers: A Survey},
year = {2023},
volume = {45},
number = {10},
issn = {1939-3539},
pages = {12113-12132},
abstract = {Transformer is a promising neural network learner, and has achieved great success in various machine learning tasks. Thanks to the recent prevalence of multimodal applications and Big Data, Transformer-based multimodal learning has become a hot topic in AI research. This paper presents a comprehensive survey of Transformer techniques oriented at multimodal data. The main contents of this survey include: (1) a background of multimodal learning, Transformer ecosystem, and the multimodal Big Data era, (2) a systematic review of Vanilla Transformer, Vision Transformer, and multimodal Transformers, from a geometrically topological perspective, (3) a review of multimodal Transformer applications, via two important paradigms, i.e., for multimodal pretraining and for specific multimodal tasks, (4) a summary of the common challenges and designs shared by the multimodal Transformer models and applications, and (5) a discussion of open problems and potential research directions for the community.},
keywords = {transformers;task analysis;surveys;visualization;taxonomy;mathematical models;data models},
doi = {10.1109/TPAMI.2023.3275156},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

 @misc{gemini2023,  title={Gemini - Google DeepMind},  url={https://deepmind.google/technologies/gemini/},  year={2023},  month={Dec} }

@InProceedings{Xue_2023_CVPR,
    author    = {Xue, Le and Gao, Mingfei and Xing, Chen and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xu, Ran and Niebles, Juan Carlos and Savarese, Silvio},
    title     = {ULIP: Learning a Unified Representation of Language, Images, and Point Clouds for 3D Understanding},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {1179-1189}
}

@book{aggarwal2018neural,
  __markedentry = {[flint:2]},
  abstract = {This book covers both classical and modern models in deep learning. The primary focus is on the theory and algorithms of deep learning. The theory and algorithms of neural networks are particularly important for understanding important concepts, so that one can understand the important design concepts of neural architectures in different applications. Why do neural networks work? When do they work better than off-the-shelf machine-learning models? When is depth useful? Why is training neural networks so hard? What are the pitfalls? The book is also rich in discussing different applications in order to give the practitioner a flavor of how neural architectures are designed for different types of problems. Applications associated with many different areas like recommender systems, machine translation, image captioning, image classification, reinforcement-learning based gaming, and text analytics are covered. The chapters of this book span three categories. First, the basics of neural networks: Many traditional machine learning models can be understood as special cases of neural networks. An emphasis is placed in the first two chapters on understanding the relationship between traditional machine learning and neural networks. Support vector machines, linear/logistic regression, singular value decomposition, matrix factorization, and recommender systems are shown to be special cases of neural networks. These methods are studied together with recent feature engineering methods like word2vec. The second part deals with Fundamentals of neural networks: A detailed discussion of training and regularization is provided in Chapters 3 and 4. Chapters 5 and 6 present radial-basis function (RBF) networks and restricted Boltzmann machines. The final part covers Advanced topics in neural networks: Chapters 7 and 8 discuss recurrent neural networks and convolutional neural networks. Several advanced topics like deep reinforcement learning, neural Turing machines, Kohonen self-organizing maps, and generative adversarial networks are introduced in Chapters 9 and 10.},
  added-at = {2021-04-12T10:31:33.000+0200},
  address = {Cham},
  author = {Aggarwal, Charu C.},
  biburl = {https://www.bibsonomy.org/bibtex/26681a2e990d3d35887d519e2ec3bd7a9/sdo},
  doi = {10.1007/978-3-319-94463-0},
  file = {copy:201x/8/Aggarwal18.pdf:PDF;shop:https\://www.springer.com/978-3-319-94462-3:text/html;archive:https\://www.springerprofessional.de/neural-networks-and-deep-learning/16073524:text/html},
  gender = {sm},
  interhash = {59b0c6aa4a43b74401bca82051990b53},
  intrahash = {6681a2e990d3d35887d519e2ec3bd7a9},
  isbn = {978-3-319-94462-3},
  keywords = {deep learning},
  owner = {flint},
  pages = 497,
  publisher = {Springer},
  referencetype = {book},
  subtitle = {A Textbook},
  timestamp = {2021-04-12T10:31:33.000+0200},
  title = {Neural Networks and Deep Learning},
  x.asin = {3319944622},
  x.sortdate = {2018-09},
  year = 2018
}

@article{sun2022benchmarking,
      title={Benchmarking Robustness of 3D Point Cloud Recognition Against Common Corruptions}, 
      author={Jiachen Sun and Qingzhao Zhang and Bhavya Kailkhura and Zhiding Yu and Chaowei Xiao and Z. Morley Mao},
      journal={arXiv preprint arXiv:2201.12296},
      year={2022}
}

@article{10.1145/3355089.3356498,
author = {Nimier-David, Merlin and Vicini, Delio and Zeltner, Tizian and Jakob, Wenzel},
title = {Mitsuba 2: A Retargetable Forward and Inverse Renderer},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3355089.3356498},
doi = {10.1145/3355089.3356498},
abstract = {Modern rendering systems are confronted with a dauntingly large and growing set of requirements: in their pursuit of realism, physically based techniques must increasingly account for intricate properties of light, such as its spectral composition or polarization. To reduce prohibitive rendering times, vectorized renderers exploit coherence via instruction-level parallelism on CPUs and GPUs. Differentiable rendering algorithms propagate derivatives through a simulation to optimize an objective function, e.g., to reconstruct a scene from reference images. Catering to such diverse use cases is challenging and has led to numerous purpose-built systems---partly, because retrofitting features of this complexity onto an existing renderer involves an error-prone and infeasibly intrusive transformation of elementary data structures, interfaces between components, and their implementations (in other words, everything).We propose Mitsuba 2, a versatile renderer that is intrinsically retargetable to various applications including the ones listed above. Mitsuba 2 is implemented in modern C++ and leverages template metaprogramming to replace types and instrument the control flow of components such as BSDFs, volumes, emitters, and rendering algorithms. At compile time, it automatically transforms arithmetic, data structures, and function dispatch, turning generic algorithms into a variety of efficient implementations without the tedium of manual redesign. Possible transformations include changing the representation of color, generating a "wide" renderer that operates on bundles of light paths, just-in-time compilation to create computational kernels that run on the GPU, and forward/reverse-mode automatic differentiation. Transformations can be chained, which further enriches the space of algorithms derived from a single generic implementation.We demonstrate the effectiveness and simplicity of our approach on several applications that would be very challenging to create without assistance: a rendering algorithm based on coherent MCMC exploration, a caustic design method for gradient-index optics, and a technique for reconstructing heterogeneous media in the presence of multiple scattering.},
journal = {ACM Trans. Graph.},
month = {nov},
articleno = {203},
numpages = {17},
keywords = {differentiable rendering, global illumination, SIMD, ray tracing}
}

@misc{pointvisualizaiton,  title={PointVisualizaiton},  url={https://github.com/qizekun/PointVisualizaiton} }

@article{10.1145/3293318,
author = {Wang, Wei and Zheng, Vincent W. and Yu, Han and Miao, Chunyan},
title = {A Survey of Zero-Shot Learning: Settings, Methods, and Applications},
year = {2019},
issue_date = {March 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3293318},
doi = {10.1145/3293318},
abstract = {Most machine-learning methods focus on classifying instances whose classes have already been seen in training. In practice, many applications require classifying instances whose classes have not been seen previously. Zero-shot learning is a powerful and promising learning paradigm, in which the classes covered by training instances and the classes we aim to classify are disjoint. In this paper, we provide a comprehensive survey of zero-shot learning. First of all, we provide an overview of zero-shot learning. According to the data utilized in model optimization, we classify zero-shot learning into three learning settings. Second, we describe different semantic spaces adopted in existing zero-shot learning works. Third, we categorize existing zero-shot learning methods and introduce representative methods under each category. Fourth, we discuss different applications of zero-shot learning. Finally, we highlight promising future research directions of zero-shot learning.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = {jan},
articleno = {13},
numpages = {37},
keywords = {Zero-shot learning survey}
}
}

@misc{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@InProceedings{Qi_2017_CVPR,
author = {Qi, Charles R. and Su, Hao and Mo, Kaichun and Guibas, Leonidas J.},
title = {PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@inproceedings{
merullo2023linearly,
title={Linearly Mapping from Image to Text Space},
author={Jack Merullo and Louis Castricato and Carsten Eickhoff and Ellie Pavlick},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=8tYRqb05pVn}
}

@inproceedings{DBLP:journals/corr/KingmaB14,
  author       = {Diederik P. Kingma and
                  Jimmy Ba},
  editor       = {Yoshua Bengio and
                  Yann LeCun},
  title        = {Adam: {A} Method for Stochastic Optimization},
  booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015,
                  San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year         = {2015},
  url          = {http://arxiv.org/abs/1412.6980},
  timestamp    = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{
ma2022rethinking,
title={Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual {MLP} Framework},
author={Xu Ma and Can Qin and Haoxuan You and Haoxi Ran and Yun Fu},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=3Pbra-_u76D}
}

@InProceedings{Zhao_2021_ICCV,
    author    = {Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip H.S. and Koltun, Vladlen},
    title     = {Point Transformer},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {16259-16268}
}

@InProceedings{Yu_2022_CVPR,
    author    = {Yu, Xumin and Tang, Lulu and Rao, Yongming and Huang, Tiejun and Zhou, Jie and Lu, Jiwen},
    title     = {Point-BERT: Pre-Training 3D Point Cloud Transformers With Masked Point Modeling},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {19313-19322}
}